{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of Haikus and of the matching images\n",
    "\n",
    "This Jupyter Notebook is dedicated to the generation of the haikus with the trained models and the matching dataset and after that, to generate a corresponding image with a StableDiffusion model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-03 19:55:29.901378: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-03 19:55:30.028361: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-03 19:55:30.062979: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-03 19:55:30.275526: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-03 19:55:31.975257: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import re\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data for the tokeniser\n",
    "\n",
    "In this first part, just like for the training notebook, we are loading the dataset corresponding to our model, so that the tokeniser is the same one as the one used for the training and to make the haikus make some sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_1</th>\n",
       "      <th>line_2</th>\n",
       "      <th>line_3</th>\n",
       "      <th>source</th>\n",
       "      <th>line1_syllables</th>\n",
       "      <th>line2_syllables</th>\n",
       "      <th>line3_syllables</th>\n",
       "      <th>haiku</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Says it all doesn't</td>\n",
       "      <td>it most of them don't even</td>\n",
       "      <td>know why they are there</td>\n",
       "      <td>twaiku</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>Says it all doesn't  it most of them don't eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cindy needed time</td>\n",
       "      <td>to take a nap on the floor</td>\n",
       "      <td>of the US Senate</td>\n",
       "      <td>twaiku</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>Cindy needed time  to take a nap on the floor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A glorious morn</td>\n",
       "      <td>Without a cloud to be seen</td>\n",
       "      <td>Why then do I cry</td>\n",
       "      <td>twaiku</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>A glorious morn  Without a cloud to be seen Wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Now playing We'll Meet</td>\n",
       "      <td>Again by Barry O'Dowd</td>\n",
       "      <td>The Shamrock Singers</td>\n",
       "      <td>twaiku</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>Now playing We'll Meet  Again by Barry O'Dowd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Watching some courage</td>\n",
       "      <td>the cowardly dog show to</td>\n",
       "      <td>start the day off right</td>\n",
       "      <td>twaiku</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>Watching some courage  the cowardly dog show t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   line_1                       line_2  \\\n",
       "0     Says it all doesn't   it most of them don't even   \n",
       "1       Cindy needed time   to take a nap on the floor   \n",
       "2         A glorious morn   Without a cloud to be seen   \n",
       "3  Now playing We'll Meet        Again by Barry O'Dowd   \n",
       "4   Watching some courage     the cowardly dog show to   \n",
       "\n",
       "                    line_3  source  line1_syllables  line2_syllables  \\\n",
       "0  know why they are there  twaiku                4                7   \n",
       "1         of the US Senate  twaiku                6                8   \n",
       "2        Why then do I cry  twaiku                4                7   \n",
       "3     The Shamrock Singers  twaiku                4                7   \n",
       "4  start the day off right  twaiku                7                7   \n",
       "\n",
       "   line3_syllables                                              haiku  \n",
       "0                7  Says it all doesn't  it most of them don't eve...  \n",
       "1                6  Cindy needed time  to take a nap on the floor ...  \n",
       "2                5  A glorious morn  Without a cloud to be seen Wh...  \n",
       "3                5  Now playing We'll Meet  Again by Barry O'Dowd ...  \n",
       "4                5  Watching some courage  the cowardly dog show t...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV data\n",
    "df = pd.read_csv('models/lstm_5000/haiku_dataset_1725314076.csv')\n",
    "\n",
    "# Display the loaded data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are cleaning our haikus after fusing them all, this will allow us to do the tokenization of our dataset after this. \n",
    "\n",
    "This is a way to do, but it is also possible to do it by using the three lines of the haikus and then having more differents lines and cases but for this first time, we will try to do it simple and then improve the project step by step with the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all haikus into a single string\n",
    "haikus = df['haiku'].tolist()\n",
    "text = ' '.join(haikus)\n",
    "\n",
    "# Clean the text\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r'\\r', '', text)\n",
    "    text = re.sub(r'\\xa0', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "cleaned_text = clean_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As now our text are cleaned, we can tokenize them and see if the result is what we could expect from this process : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[327, 16], [327, 16, 28], [327, 16, 28, 213], [327, 16, 28, 213, 16], [327, 16, 28, 213, 16, 186], [327, 16, 28, 213, 16, 186, 8], [327, 16, 28, 213, 16, 186, 8, 80], [327, 16, 28, 213, 16, 186, 8, 80, 29], [327, 16, 28, 213, 16, 186, 8, 80, 29, 76], [327, 16, 28, 213, 16, 186, 8, 80, 29, 76, 61]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([cleaned_text])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Convert haikus to sequences of tokens\n",
    "input_sequences = []\n",
    "for haiku in haikus:\n",
    "    token_list = tokenizer.texts_to_sequences([clean_text(haiku)])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "print(input_sequences[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haikus generation\n",
    "\n",
    "Now we will be generating a haikus using a random seed. \n",
    "\n",
    "This code is mainly here to show a single haiku generation but it is the same one as the training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meanwhile in the real world migration is back to pre crisis levels\n",
      "['meanwhile in the', ' real world migration is back', ' to pre crisis levels']\n"
     ]
    }
   ],
   "source": [
    "# You can find the corresponding functions in the functions.py file\n",
    "from functions import *\n",
    "\n",
    "# Example usage\n",
    "seed_word = select_random_seed_word_from_tokenizer(tokenizer)\n",
    "\n",
    "params = {\n",
    "    'model_path': 'models/lstm_5000/haiku_model_1725314076.keras',\n",
    "    'seed_text': seed_word,\n",
    "    'syllables_mode': True,\n",
    "    'words_mode': False,\n",
    "    'haikus_pattern': [5, 7, 5],\n",
    "    'max_sequence_len': 21,\n",
    "    'tokenizer': tokenizer  # Assuming tokenizer is already defined\n",
    "}\n",
    "\n",
    "seed_text, haiku = generate_haiku_from_params(params)\n",
    "print(seed_text)\n",
    "print(haiku)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of multiples haikus \n",
    "\n",
    "In this part we will be generating a given number of haikus in a folder that will be created to store them. \n",
    "\n",
    "We are doing so we will be able to identify each of them individually to after that generate the corresponding image with Stable Diffusion ! This is also to see what the haikus generated randomly can be about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haiku 1 saved to generated_haikus_100/haiku_1.txt\n",
      "Haiku 2 saved to generated_haikus_100/haiku_2.txt\n",
      "Haiku 3 saved to generated_haikus_100/haiku_3.txt\n",
      "Haiku 4 saved to generated_haikus_100/haiku_4.txt\n",
      "Haiku 5 saved to generated_haikus_100/haiku_5.txt\n",
      "Haiku 6 saved to generated_haikus_100/haiku_6.txt\n",
      "Haiku 7 saved to generated_haikus_100/haiku_7.txt\n",
      "Haiku 8 saved to generated_haikus_100/haiku_8.txt\n",
      "Haiku 9 saved to generated_haikus_100/haiku_9.txt\n",
      "Haiku 10 saved to generated_haikus_100/haiku_10.txt\n",
      "Haiku 11 saved to generated_haikus_100/haiku_11.txt\n",
      "Haiku 12 saved to generated_haikus_100/haiku_12.txt\n",
      "Haiku 13 saved to generated_haikus_100/haiku_13.txt\n",
      "Haiku 14 saved to generated_haikus_100/haiku_14.txt\n",
      "Haiku 15 saved to generated_haikus_100/haiku_15.txt\n",
      "Haiku 16 saved to generated_haikus_100/haiku_16.txt\n",
      "Haiku 17 saved to generated_haikus_100/haiku_17.txt\n",
      "Haiku 18 saved to generated_haikus_100/haiku_18.txt\n",
      "Haiku 19 saved to generated_haikus_100/haiku_19.txt\n",
      "Haiku 20 saved to generated_haikus_100/haiku_20.txt\n",
      "Haiku 21 saved to generated_haikus_100/haiku_21.txt\n",
      "Haiku 22 saved to generated_haikus_100/haiku_22.txt\n",
      "Haiku 23 saved to generated_haikus_100/haiku_23.txt\n",
      "Haiku 24 saved to generated_haikus_100/haiku_24.txt\n",
      "Haiku 25 saved to generated_haikus_100/haiku_25.txt\n",
      "Haiku 26 saved to generated_haikus_100/haiku_26.txt\n",
      "Haiku 27 saved to generated_haikus_100/haiku_27.txt\n",
      "Haiku 28 saved to generated_haikus_100/haiku_28.txt\n",
      "Haiku 29 saved to generated_haikus_100/haiku_29.txt\n",
      "Haiku 30 saved to generated_haikus_100/haiku_30.txt\n",
      "Haiku 31 saved to generated_haikus_100/haiku_31.txt\n",
      "Haiku 32 saved to generated_haikus_100/haiku_32.txt\n",
      "Haiku 33 saved to generated_haikus_100/haiku_33.txt\n",
      "Haiku 34 saved to generated_haikus_100/haiku_34.txt\n",
      "Haiku 35 saved to generated_haikus_100/haiku_35.txt\n",
      "Haiku 36 saved to generated_haikus_100/haiku_36.txt\n",
      "Haiku 37 saved to generated_haikus_100/haiku_37.txt\n",
      "Haiku 38 saved to generated_haikus_100/haiku_38.txt\n",
      "Haiku 39 saved to generated_haikus_100/haiku_39.txt\n",
      "Haiku 40 saved to generated_haikus_100/haiku_40.txt\n",
      "Haiku 41 saved to generated_haikus_100/haiku_41.txt\n",
      "Haiku 42 saved to generated_haikus_100/haiku_42.txt\n",
      "Haiku 43 saved to generated_haikus_100/haiku_43.txt\n",
      "Haiku 44 saved to generated_haikus_100/haiku_44.txt\n",
      "Haiku 45 saved to generated_haikus_100/haiku_45.txt\n",
      "Haiku 46 saved to generated_haikus_100/haiku_46.txt\n",
      "Haiku 47 saved to generated_haikus_100/haiku_47.txt\n",
      "Haiku 48 saved to generated_haikus_100/haiku_48.txt\n",
      "Haiku 49 saved to generated_haikus_100/haiku_49.txt\n",
      "Haiku 50 saved to generated_haikus_100/haiku_50.txt\n",
      "Haiku 51 saved to generated_haikus_100/haiku_51.txt\n",
      "Haiku 52 saved to generated_haikus_100/haiku_52.txt\n",
      "Haiku 53 saved to generated_haikus_100/haiku_53.txt\n",
      "Haiku 54 saved to generated_haikus_100/haiku_54.txt\n",
      "Haiku 55 saved to generated_haikus_100/haiku_55.txt\n",
      "Haiku 56 saved to generated_haikus_100/haiku_56.txt\n",
      "Haiku 57 saved to generated_haikus_100/haiku_57.txt\n",
      "Haiku 58 saved to generated_haikus_100/haiku_58.txt\n",
      "Haiku 59 saved to generated_haikus_100/haiku_59.txt\n",
      "Haiku 60 saved to generated_haikus_100/haiku_60.txt\n",
      "Haiku 61 saved to generated_haikus_100/haiku_61.txt\n",
      "Haiku 62 saved to generated_haikus_100/haiku_62.txt\n",
      "Haiku 63 saved to generated_haikus_100/haiku_63.txt\n",
      "Haiku 64 saved to generated_haikus_100/haiku_64.txt\n",
      "Haiku 65 saved to generated_haikus_100/haiku_65.txt\n",
      "Haiku 66 saved to generated_haikus_100/haiku_66.txt\n",
      "Haiku 67 saved to generated_haikus_100/haiku_67.txt\n",
      "Haiku 68 saved to generated_haikus_100/haiku_68.txt\n",
      "Haiku 69 saved to generated_haikus_100/haiku_69.txt\n",
      "Haiku 70 saved to generated_haikus_100/haiku_70.txt\n",
      "Haiku 71 saved to generated_haikus_100/haiku_71.txt\n",
      "Haiku 72 saved to generated_haikus_100/haiku_72.txt\n",
      "Haiku 73 saved to generated_haikus_100/haiku_73.txt\n",
      "Haiku 74 saved to generated_haikus_100/haiku_74.txt\n",
      "Haiku 75 saved to generated_haikus_100/haiku_75.txt\n",
      "Haiku 76 saved to generated_haikus_100/haiku_76.txt\n",
      "Haiku 77 saved to generated_haikus_100/haiku_77.txt\n",
      "Haiku 78 saved to generated_haikus_100/haiku_78.txt\n",
      "Haiku 79 saved to generated_haikus_100/haiku_79.txt\n",
      "Haiku 80 saved to generated_haikus_100/haiku_80.txt\n",
      "Haiku 81 saved to generated_haikus_100/haiku_81.txt\n",
      "Haiku 82 saved to generated_haikus_100/haiku_82.txt\n",
      "Haiku 83 saved to generated_haikus_100/haiku_83.txt\n",
      "Haiku 84 saved to generated_haikus_100/haiku_84.txt\n",
      "Haiku 85 saved to generated_haikus_100/haiku_85.txt\n",
      "Haiku 86 saved to generated_haikus_100/haiku_86.txt\n",
      "Haiku 87 saved to generated_haikus_100/haiku_87.txt\n",
      "Haiku 88 saved to generated_haikus_100/haiku_88.txt\n",
      "Haiku 89 saved to generated_haikus_100/haiku_89.txt\n",
      "Haiku 90 saved to generated_haikus_100/haiku_90.txt\n",
      "Haiku 91 saved to generated_haikus_100/haiku_91.txt\n",
      "Haiku 92 saved to generated_haikus_100/haiku_92.txt\n",
      "Haiku 93 saved to generated_haikus_100/haiku_93.txt\n",
      "Haiku 94 saved to generated_haikus_100/haiku_94.txt\n",
      "Haiku 95 saved to generated_haikus_100/haiku_95.txt\n",
      "Haiku 96 saved to generated_haikus_100/haiku_96.txt\n",
      "Haiku 97 saved to generated_haikus_100/haiku_97.txt\n",
      "Haiku 98 saved to generated_haikus_100/haiku_98.txt\n",
      "Haiku 99 saved to generated_haikus_100/haiku_99.txt\n",
      "Haiku 100 saved to generated_haikus_100/haiku_100.txt\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'model_path': 'models/lstm_5000/haiku_model_1725314076.keras',\n",
    "    'seed_text': seed_word,\n",
    "    'syllables_mode': True,\n",
    "    'words_mode': False,\n",
    "    'haikus_pattern': [5, 7, 5],\n",
    "    'max_sequence_len': 21,\n",
    "    'tokenizer': tokenizer  # Assuming tokenizer is already defined\n",
    "}\n",
    "\n",
    "# Create a folder to save the haikus\n",
    "output_folder = 'generated_haikus_100'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Generate and save 10 haikus\n",
    "for i in range(100):\n",
    "    seed_word = select_random_seed_word_from_tokenizer(tokenizer)\n",
    "    params['seed_text'] = seed_word\n",
    "    seed_text, haiku = generate_haiku_from_params(params)\n",
    "    \n",
    "    # Create a string with \\n at the end of each element of the haiku list, stripping any leading/trailing whitespace\n",
    "    haiku_string = \"\\n\".join(line.strip() for line in haiku)\n",
    "\n",
    "    # Save the haiku to a text file\n",
    "    haiku_filename = os.path.join(output_folder, f'haiku_{i+1}.txt')\n",
    "    with open(haiku_filename, 'w') as file:\n",
    "        file.write(haiku_string)\n",
    "    \n",
    "    print(f'Haiku {i+1} saved to {haiku_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image from haikus generation\n",
    "\n",
    "In this final part, we will be loading the pipeline of Stable Diffusion and then open and read all of the haikus to then generate a corresponding image with the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hook/.pyenv/versions/3.10.13/envs/haikus/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]/home/hook/.pyenv/versions/3.10.13/envs/haikus/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable Diffusion pipeline loaded\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DDPMScheduler\n",
    "from PIL import Image\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", variant=\"fp16\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "\n",
    "print(\"Stable Diffusion pipeline loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:51<00:00,  9.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_10.txt saved to generated_haikus_100/haiku_10.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:24<00:00,  8.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_12.txt saved to generated_haikus_100/haiku_12.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:08<00:00,  8.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_86.txt saved to generated_haikus_100/haiku_86.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:13<00:00,  8.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_27.txt saved to generated_haikus_100/haiku_27.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:01<00:00,  8.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_11.txt saved to generated_haikus_100/haiku_11.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:14<00:00,  8.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_40.txt saved to generated_haikus_100/haiku_40.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:20<00:00,  8.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_39.txt saved to generated_haikus_100/haiku_39.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:28<00:00,  8.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_89.txt saved to generated_haikus_100/haiku_89.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:20<00:00,  8.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_68.txt saved to generated_haikus_100/haiku_68.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:08<00:00,  8.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_37.txt saved to generated_haikus_100/haiku_37.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:06<00:00,  8.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_59.txt saved to generated_haikus_100/haiku_59.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:26<00:00,  7.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_87.txt saved to generated_haikus_100/haiku_87.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:12<00:00,  8.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_90.txt saved to generated_haikus_100/haiku_90.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:45<00:00,  8.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_67.txt saved to generated_haikus_100/haiku_67.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:06<00:00,  8.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_73.txt saved to generated_haikus_100/haiku_73.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:07<00:00,  8.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_93.txt saved to generated_haikus_100/haiku_93.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:10<00:00,  8.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_53.txt saved to generated_haikus_100/haiku_53.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:48<00:00,  8.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_100.txt saved to generated_haikus_100/haiku_100.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:10<00:00,  8.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_91.txt saved to generated_haikus_100/haiku_91.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:09<00:00,  8.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_60.txt saved to generated_haikus_100/haiku_60.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:44<00:00,  8.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_2.txt saved to generated_haikus_100/haiku_2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:03<00:00,  8.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_82.txt saved to generated_haikus_100/haiku_82.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:09<00:00,  8.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_25.txt saved to generated_haikus_100/haiku_25.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:27<00:00,  8.95s/it]\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_8.txt saved to generated_haikus_100/haiku_8.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:46<00:00,  8.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_81.txt saved to generated_haikus_100/haiku_81.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:21<00:00,  8.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_62.txt saved to generated_haikus_100/haiku_62.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:16<00:00,  8.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_69.txt saved to generated_haikus_100/haiku_69.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:13<00:00,  8.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_24.txt saved to generated_haikus_100/haiku_24.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:19<00:00,  8.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_49.txt saved to generated_haikus_100/haiku_49.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:01<00:00,  8.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_34.txt saved to generated_haikus_100/haiku_34.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:04<00:00,  8.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_22.txt saved to generated_haikus_100/haiku_22.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:03<00:00,  8.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_1.txt saved to generated_haikus_100/haiku_1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:29<00:00,  8.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_21.txt saved to generated_haikus_100/haiku_21.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:16<00:00,  8.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_63.txt saved to generated_haikus_100/haiku_63.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:07<00:00,  8.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_99.txt saved to generated_haikus_100/haiku_99.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:13<00:00,  8.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_58.txt saved to generated_haikus_100/haiku_58.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:03<00:00,  8.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_76.txt saved to generated_haikus_100/haiku_76.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:52<00:00,  8.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_45.txt saved to generated_haikus_100/haiku_45.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:16<00:00,  8.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_88.txt saved to generated_haikus_100/haiku_88.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:57<00:00,  8.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_94.txt saved to generated_haikus_100/haiku_94.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:54<00:00,  8.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_5.txt saved to generated_haikus_100/haiku_5.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:20<00:00,  8.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_35.txt saved to generated_haikus_100/haiku_35.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:01<00:00,  8.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_9.txt saved to generated_haikus_100/haiku_9.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:10<00:00,  8.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_38.txt saved to generated_haikus_100/haiku_38.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:59<00:00,  8.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_80.txt saved to generated_haikus_100/haiku_80.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:21<00:00,  8.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_14.txt saved to generated_haikus_100/haiku_14.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:15<00:00,  8.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_48.txt saved to generated_haikus_100/haiku_48.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:34<00:00,  9.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_16.txt saved to generated_haikus_100/haiku_16.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:04<00:00,  8.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_3.txt saved to generated_haikus_100/haiku_3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:26<00:00,  8.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_33.txt saved to generated_haikus_100/haiku_33.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:05<00:00,  8.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_7.txt saved to generated_haikus_100/haiku_7.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:28<00:00,  8.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_52.txt saved to generated_haikus_100/haiku_52.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:11<00:00,  8.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_56.txt saved to generated_haikus_100/haiku_56.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:42<00:00,  8.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_54.txt saved to generated_haikus_100/haiku_54.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:11<00:00,  8.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_42.txt saved to generated_haikus_100/haiku_42.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:17<00:00,  8.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_79.txt saved to generated_haikus_100/haiku_79.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:10<00:00,  8.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_13.txt saved to generated_haikus_100/haiku_13.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:48<00:00,  8.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_75.txt saved to generated_haikus_100/haiku_75.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:04<00:00,  8.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_4.txt saved to generated_haikus_100/haiku_4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:55<00:00,  8.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_26.txt saved to generated_haikus_100/haiku_26.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:54<00:00,  8.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_95.txt saved to generated_haikus_100/haiku_95.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:50<00:00,  8.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_19.txt saved to generated_haikus_100/haiku_19.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:07<00:00,  8.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_29.txt saved to generated_haikus_100/haiku_29.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:14<00:00,  8.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_66.txt saved to generated_haikus_100/haiku_66.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:57<00:00,  8.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_65.txt saved to generated_haikus_100/haiku_65.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:09<00:00,  8.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_44.txt saved to generated_haikus_100/haiku_44.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:57<00:00,  8.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_61.txt saved to generated_haikus_100/haiku_61.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:16<00:00,  8.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_78.txt saved to generated_haikus_100/haiku_78.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:11<00:00,  8.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_36.txt saved to generated_haikus_100/haiku_36.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:06<00:00,  8.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_23.txt saved to generated_haikus_100/haiku_23.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:11<00:00,  8.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_6.txt saved to generated_haikus_100/haiku_6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:04<00:00,  8.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_17.txt saved to generated_haikus_100/haiku_17.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:05<00:00,  8.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_18.txt saved to generated_haikus_100/haiku_18.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:19<00:00,  8.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_64.txt saved to generated_haikus_100/haiku_64.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:55<00:00,  8.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_96.txt saved to generated_haikus_100/haiku_96.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:50<00:00,  8.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_83.txt saved to generated_haikus_100/haiku_83.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:07<00:00,  8.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_85.txt saved to generated_haikus_100/haiku_85.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:12<00:00,  8.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_51.txt saved to generated_haikus_100/haiku_51.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:36<00:00,  7.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_15.txt saved to generated_haikus_100/haiku_15.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:10<00:00,  8.62s/it]\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_92.txt saved to generated_haikus_100/haiku_92.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:34<00:00,  7.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_55.txt saved to generated_haikus_100/haiku_55.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:58<00:00,  8.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_72.txt saved to generated_haikus_100/haiku_72.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:48<00:00,  8.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_30.txt saved to generated_haikus_100/haiku_30.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:04<00:00,  8.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_46.txt saved to generated_haikus_100/haiku_46.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:13<00:00,  8.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_31.txt saved to generated_haikus_100/haiku_31.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:18<00:00,  8.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_98.txt saved to generated_haikus_100/haiku_98.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:22<00:00,  8.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_71.txt saved to generated_haikus_100/haiku_71.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:38<00:00,  7.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_77.txt saved to generated_haikus_100/haiku_77.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:13<00:00,  8.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_32.txt saved to generated_haikus_100/haiku_32.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:06<00:00,  8.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_74.txt saved to generated_haikus_100/haiku_74.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:04<00:00,  8.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_97.txt saved to generated_haikus_100/haiku_97.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:09<00:00,  8.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_41.txt saved to generated_haikus_100/haiku_41.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:01<00:00,  8.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_50.txt saved to generated_haikus_100/haiku_50.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:51<00:00,  8.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_47.txt saved to generated_haikus_100/haiku_47.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:07<00:00,  8.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_70.txt saved to generated_haikus_100/haiku_70.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:16<00:00,  8.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_84.txt saved to generated_haikus_100/haiku_84.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:36<00:00,  7.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_57.txt saved to generated_haikus_100/haiku_57.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:59<00:00,  8.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_43.txt saved to generated_haikus_100/haiku_43.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:25<00:00,  7.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_20.txt saved to generated_haikus_100/haiku_20.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:14<00:00,  8.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for haiku_28.txt saved to generated_haikus_100/haiku_28.png\n"
     ]
    }
   ],
   "source": [
    "# Folder containing the haikus\n",
    "haiku_folder = 'generated_haikus_100'\n",
    "\n",
    "# List all .txt files in the folder\n",
    "haiku_files = [f for f in os.listdir(haiku_folder) if f.endswith('.txt')]\n",
    "\n",
    "# Function to generate image from text\n",
    "def generate_image_from_text(text, output_path):\n",
    "    prompt = text\n",
    "    scheduler = DDPMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\")\n",
    "    image = pipe(prompt, scheduler=scheduler, num_inference_steps=50, guidance_scale=5.0).images[0]\n",
    "    image.save(output_path)\n",
    "\n",
    "# Iterate over each haiku file and generate the corresponding image\n",
    "for haiku_file in haiku_files:\n",
    "    haiku_path = os.path.join(haiku_folder, haiku_file)\n",
    "    \n",
    "    # Read the haiku text\n",
    "    with open(haiku_path, 'r') as file:\n",
    "        haiku_text = file.read()\n",
    "    \n",
    "    # Generate the image\n",
    "    image_output_path = os.path.join(haiku_folder, haiku_file.replace('.txt', '.png'))\n",
    "    generate_image_from_text(haiku_text, image_output_path)\n",
    "    \n",
    "    print(f'Image for {haiku_file} saved to {image_output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This really simple last part is mostly just to play with Stable Diffusion and see some funny results that can be generated with it and the generated haikus. The results were fun and this it was a really nice thing to discover as I never used Stable Diffusion models before !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haikus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
