{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Complete Notebook\n",
    "\n",
    "This notebook is made to do the complete data processing of our data. It will mostly cover the cleaning process and merging process of the datasets. This notebook will cover the following :\n",
    "\n",
    "- Data Cleaning: Handling missing values, removing duplicates, and correcting data types.\n",
    "\n",
    "- Data Integration: Merging datasets, joining tables, and aggregating data.\n",
    "\n",
    "With this done, we will be able to use our two haikus datasets, the french and the english dataset, to train our model after treating them for our training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temps libre loading\n",
    "\n",
    "In this section, we are processing data from the Temps Libre website, which I scraped using my custom code. \n",
    "The code used for scraping can be found at the following link: [Scraping Code](insert-your-link-here)\n",
    "\n",
    "This step involves cleaning and preparing the haiku data for further analysis and use in our project.\n",
    "\n",
    "This website was found in the list of this GitHub during my research about the subject : [haiku-scraper's GitHub](https://github.com/ytixu/haiku-scraper/tree/master).\n",
    "\n",
    "This is the website that has be scrapped to get this data : [Temps libre](https://www.tempslibres.org/tl/tlphp/dblang.php?lg=e). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset lenght : 5664\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_1</th>\n",
       "      <th>line_2</th>\n",
       "      <th>line_3</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zen garden --</td>\n",
       "      <td>stirring a passing cloud</td>\n",
       "      <td>in my tea</td>\n",
       "      <td>tempslibre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mosquee blackout</td>\n",
       "      <td>I come home</td>\n",
       "      <td>with new slippers</td>\n",
       "      <td>tempslibre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fishing boats</td>\n",
       "      <td>colors of</td>\n",
       "      <td>the rainbow</td>\n",
       "      <td>tempslibre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ash wednesday--</td>\n",
       "      <td>trying to remember</td>\n",
       "      <td>my dream</td>\n",
       "      <td>tempslibre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>snowy morn--</td>\n",
       "      <td>pouring another cup</td>\n",
       "      <td>of black coffee</td>\n",
       "      <td>tempslibre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             line_1                    line_2             line_3      source\n",
       "0     zen garden --  stirring a passing cloud          in my tea  tempslibre\n",
       "1  mosquee blackout               I come home  with new slippers  tempslibre\n",
       "2     fishing boats                 colors of        the rainbow  tempslibre\n",
       "3   ash wednesday--       trying to remember            my dream  tempslibre\n",
       "4      snowy morn--       pouring another cup    of black coffee  tempslibre"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the file\n",
    "df_tl_en = pd.read_csv('database/raw_data/english_tempslibre_csv.csv', encoding='utf8')\n",
    "\n",
    "print(f\"Dataset lenght : {len(df_tl_en)}\")\n",
    "df_tl_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset lenght : 9942\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_1</th>\n",
       "      <th>line_2</th>\n",
       "      <th>line_3</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sur une colonne en bois</td>\n",
       "      <td>le vendeur des ballons</td>\n",
       "      <td>hisse ses souffles</td>\n",
       "      <td>tempslibre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nuit froide marchant seule</td>\n",
       "      <td>d'une maison une odeur</td>\n",
       "      <td>de beignets au sucre</td>\n",
       "      <td>tempslibre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brume matinale</td>\n",
       "      <td>dans la tasse de café</td>\n",
       "      <td>la buée de l’arome</td>\n",
       "      <td>tempslibre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>averse au jardin</td>\n",
       "      <td>elle a fait naufrage</td>\n",
       "      <td>la tarte aux pommes</td>\n",
       "      <td>tempslibre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sécheresse</td>\n",
       "      <td>dans l’eau vaseuse</td>\n",
       "      <td>un ibis blanc</td>\n",
       "      <td>tempslibre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       line_1                  line_2                 line_3  \\\n",
       "0     Sur une colonne en bois  le vendeur des ballons    hisse ses souffles    \n",
       "1  Nuit froide marchant seule  d'une maison une odeur  de beignets au sucre    \n",
       "2              brume matinale   dans la tasse de café    la buée de l’arome    \n",
       "3            averse au jardin    elle a fait naufrage   la tarte aux pommes    \n",
       "4                  sécheresse      dans l’eau vaseuse         un ibis blanc    \n",
       "\n",
       "       source  \n",
       "0  tempslibre  \n",
       "1  tempslibre  \n",
       "2  tempslibre  \n",
       "3  tempslibre  \n",
       "4  tempslibre  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the file\n",
    "df_tl_fr_1 = pd.read_csv('database/raw_data/french_tempslibre_csv.csv', encoding='utf8')\n",
    "df_tl_fr_2 = pd.read_csv('database/raw_data/french_2_tempslibre_csv.csv', encoding='utf8')\n",
    "\n",
    "# Concat the two french csv into one\n",
    "dfs_tl_fr_1_2 = [df_tl_fr_1, df_tl_fr_2]\n",
    "df_tl_fr = pd.concat(dfs_tl_fr_1_2)\n",
    "\n",
    "print(f\"Dataset lenght : {len(df_tl_fr)}\")\n",
    "df_tl_fr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Herons Nest loading\n",
    "\n",
    "In this section, we are processing data from the Herons Nest website, which I scraped using my custom code. \n",
    "The code used for scraping can be found at the following link: [Scraping Code](insert-your-link-here)\n",
    "\n",
    "This step involves cleaning and preparing the haiku data for further analysis and use in our project.\n",
    "\n",
    "This website was found in the list of this GitHub during my research about the subject : [haiku-scraper's GitHub](https://github.com/ytixu/haiku-scraper/tree/master).\n",
    "\n",
    "This is the website that has be scrapped to get this data : [Herons Nest](https://theheronsnest.com/June2024/index.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset lenght : 1925\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_1</th>\n",
       "      <th>line_2</th>\n",
       "      <th>line_3</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>early spring</td>\n",
       "      <td>a hint of green</td>\n",
       "      <td>in your eyes</td>\n",
       "      <td>herons_nest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new home</td>\n",
       "      <td>morning birdsong</td>\n",
       "      <td>in a different key</td>\n",
       "      <td>herons_nest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quilting squares...</td>\n",
       "      <td>the repeating patterns</td>\n",
       "      <td>of a life</td>\n",
       "      <td>herons_nest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>putting away</td>\n",
       "      <td>my mother's letters</td>\n",
       "      <td>tulips in bloom</td>\n",
       "      <td>herons_nest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bullet train</td>\n",
       "      <td>just a glimpse</td>\n",
       "      <td>of the rice farmer</td>\n",
       "      <td>herons_nest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                line_1                  line_2              line_3  \\\n",
       "0         early spring         a hint of green        in your eyes   \n",
       "1             new home        morning birdsong  in a different key   \n",
       "2  quilting squares...  the repeating patterns           of a life   \n",
       "3         putting away     my mother's letters     tulips in bloom   \n",
       "4         bullet train          just a glimpse  of the rice farmer   \n",
       "\n",
       "        source  \n",
       "0  herons_nest  \n",
       "1  herons_nest  \n",
       "2  herons_nest  \n",
       "3  herons_nest  \n",
       "4  herons_nest  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the file\n",
    "df_hn_en = pd.read_csv('database/raw_data/heronsnest_csv.csv', encoding='utf8')\n",
    "\n",
    "print(f\"Dataset lenght : {len(df_hn_en)}\")\n",
    "df_hn_en.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modern Haikus Loading\n",
    "\n",
    "In this section, we are processing data from the Modern Haikus website, which I scraped using my custom code. \n",
    "The code used for scraping can be found at the following link: [Scraping Code](insert-your-link-here)\n",
    "\n",
    "This step involves cleaning and preparing the haiku data for further analysis and use in our project.\n",
    "\n",
    "This website was found in the list of this GitHub during my research about the subject : [haiku-scraper's GitHub](https://github.com/ytixu/haiku-scraper/tree/master).\n",
    "\n",
    "This is the website that has be scrapped to get this data : [Moderns Haikus](http://www.modernhaiku.org/previousissue.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset lenght : 369\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_1</th>\n",
       "      <th>line_2</th>\n",
       "      <th>line_3</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>voicemail —</td>\n",
       "      <td>the immediacy</td>\n",
       "      <td>of winter rain</td>\n",
       "      <td>modern_haikus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wind chimes</td>\n",
       "      <td>the laughter of grandchildren</td>\n",
       "      <td>all moved away</td>\n",
       "      <td>modern_haikus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>highschool</td>\n",
       "      <td>trophy case —</td>\n",
       "      <td>her maiden name</td>\n",
       "      <td>modern_haikus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>holding our breaths</td>\n",
       "      <td>releasing them</td>\n",
       "      <td>humpbacks</td>\n",
       "      <td>modern_haikus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Groundhog Day</td>\n",
       "      <td>motorcyclists see</td>\n",
       "      <td>their shadows</td>\n",
       "      <td>modern_haikus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                line_1                         line_2           line_3  \\\n",
       "0          voicemail —                  the immediacy   of winter rain   \n",
       "1          wind chimes  the laughter of grandchildren   all moved away   \n",
       "2           highschool                  trophy case —  her maiden name   \n",
       "3  holding our breaths                 releasing them        humpbacks   \n",
       "4        Groundhog Day              motorcyclists see    their shadows   \n",
       "\n",
       "          source  \n",
       "0  modern_haikus  \n",
       "1  modern_haikus  \n",
       "2  modern_haikus  \n",
       "3  modern_haikus  \n",
       "4  modern_haikus  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the file\n",
    "df_mh_en = pd.read_csv('database/raw_data/modern_haikus_csv.csv', encoding='utf8')\n",
    "\n",
    "print(f\"Dataset lenght : {len(df_mh_en)}\")\n",
    "df_mh_en.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github Haikuzao Txt Data Loading\n",
    "\n",
    "In this section, we are processing data from a GitHub repository that I found during my research. This data will be treated and prepared for our usage.\n",
    "\n",
    "As observed, there are too few French haikus (and some of them are actually in English), so we will not keep them.\n",
    "\n",
    "Source: [Haikuzao's Github](https://github.com/herval/creative_machines/tree/master/haikuzao) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English dataset lenght : 4725\n",
      "French dataset lenght : 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_1</th>\n",
       "      <th>line_2</th>\n",
       "      <th>line_3</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a skein of birds</td>\n",
       "      <td>twines across the sky</td>\n",
       "      <td>the northbound train departs</td>\n",
       "      <td>haikuzao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dawn chorus begins</td>\n",
       "      <td>I reach for</td>\n",
       "      <td>the snooze button</td>\n",
       "      <td>haikuzao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new March snow</td>\n",
       "      <td>the grouse with a missing toe</td>\n",
       "      <td>still around</td>\n",
       "      <td>haikuzao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Remembrance Day-</td>\n",
       "      <td>even the traffic</td>\n",
       "      <td>pauses for 2 minutes</td>\n",
       "      <td>haikuzao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dignified march-</td>\n",
       "      <td>veterans and peacekeepers</td>\n",
       "      <td>pass the applause</td>\n",
       "      <td>haikuzao</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               line_1                         line_2  \\\n",
       "0    a skein of birds          twines across the sky   \n",
       "1  dawn chorus begins                    I reach for   \n",
       "2      new March snow  the grouse with a missing toe   \n",
       "3    Remembrance Day-               even the traffic   \n",
       "4    dignified march-      veterans and peacekeepers   \n",
       "\n",
       "                         line_3    source  \n",
       "0  the northbound train departs  haikuzao  \n",
       "1             the snooze button  haikuzao  \n",
       "2                  still around  haikuzao  \n",
       "3          pauses for 2 minutes  haikuzao  \n",
       "4             pass the applause  haikuzao  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('database/raw_data/haikuzao_data.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "df_hg = [i for i in text.split('\\n\\n') if len(i.split('\\n')) == 3]\n",
    "\n",
    "df_hg_en_list = []\n",
    "df_hg_fr_list = []\n",
    "\n",
    "for h in df_hg :\n",
    "    h_splitted = h.split('\\n')\n",
    "    h_str = h_splitted[0] + \" \" + h_splitted[1] + \" \" + h_splitted[2]\n",
    "    if detect(h_str) == \"en\" :\n",
    "        df_hg_en_list.append(h_splitted)\n",
    "    elif detect(h_str) == \"fr\" :\n",
    "        df_hg_fr_list.append(h_splitted)\n",
    "\n",
    "cols_names = [\"line_1\", \"line_2\", \"line_3\"]\n",
    "df_hg_eng = pd.DataFrame(df_hg_en_list, columns=cols_names)\n",
    "df_hg_fr = pd.DataFrame(df_hg_fr_list, columns=cols_names)\n",
    "\n",
    "print(f\"English dataset lenght : {len(df_hg_eng)}\")\n",
    "print(f\"French dataset lenght : {len(df_hg_fr)}\")\n",
    "\n",
    "df_hg_eng['source'] = 'haikuzao'\n",
    "df_hg_eng.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Haikus dataset Loading\n",
    "\n",
    "In this section, we are processing data from a Kaggle that I found during my research. This data will be treated and prepared for our usage.\n",
    "\n",
    "Source: [Kaggle's Page](https://www.kaggle.com/datasets/hjhalani30/haiku-dataset?resource=download) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset lenght : 144123\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_1</th>\n",
       "      <th>line_2</th>\n",
       "      <th>line_3</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fishing boats</td>\n",
       "      <td>colors of</td>\n",
       "      <td>the rainbow</td>\n",
       "      <td>tempslibres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ash wednesday--</td>\n",
       "      <td>trying to remember</td>\n",
       "      <td>my dream</td>\n",
       "      <td>tempslibres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>snowy morn--</td>\n",
       "      <td>pouring another cup</td>\n",
       "      <td>of black coffee</td>\n",
       "      <td>tempslibres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shortest day</td>\n",
       "      <td>flames dance</td>\n",
       "      <td>in the oven</td>\n",
       "      <td>tempslibres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haze</td>\n",
       "      <td>half the horse hidden</td>\n",
       "      <td>behind the house</td>\n",
       "      <td>tempslibres</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            line_1                 line_2            line_3       source\n",
       "0    fishing boats              colors of       the rainbow  tempslibres\n",
       "1  ash wednesday--    trying to remember           my dream  tempslibres\n",
       "2     snowy morn--    pouring another cup   of black coffee  tempslibres\n",
       "3     shortest day           flames dance       in the oven  tempslibres\n",
       "4             haze  half the horse hidden  behind the house  tempslibres"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "df_kaggle = pd.read_csv('database/raw_data/all_haiku_kaggle.csv')\n",
    "\n",
    "df_kaggle = df_kaggle.drop(columns=['Unnamed: 0', 'hash'])\n",
    "df_kaggle.columns = ['line_1', 'line_2', 'line_3', 'source']\n",
    "\n",
    "# Display the first 5 lines\n",
    "print(f\"Dataset lenght : {len(df_kaggle)}\")\n",
    "df_kaggle.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Final Two CSV Files (English and French)\n",
    "\n",
    "In this section, we will combine and save all of our datasets into two comprehensive CSV files—one for English and one for French.\n",
    "\n",
    "This approach will enable us to reuse the data later without needing to process all of our datasets again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final english dataset lenght : 156806\n",
      "Final french dataset lenght : 9942\n",
      "             line_1                    line_2             line_3      source\n",
      "0     zen garden --  stirring a passing cloud          in my tea  tempslibre\n",
      "1  mosquee blackout               I come home  with new slippers  tempslibre\n",
      "2     fishing boats                 colors of        the rainbow  tempslibre\n",
      "3   ash wednesday--       trying to remember            my dream  tempslibre\n",
      "4      snowy morn--       pouring another cup    of black coffee  tempslibre\n",
      "                       line_1                  line_2                 line_3  \\\n",
      "0     Sur une colonne en bois  le vendeur des ballons    hisse ses souffles    \n",
      "1  Nuit froide marchant seule  d'une maison une odeur  de beignets au sucre    \n",
      "2              brume matinale   dans la tasse de café    la buée de l’arome    \n",
      "3            averse au jardin    elle a fait naufrage   la tarte aux pommes    \n",
      "4                  sécheresse      dans l’eau vaseuse         un ibis blanc    \n",
      "\n",
      "       source  \n",
      "0  tempslibre  \n",
      "1  tempslibre  \n",
      "2  tempslibre  \n",
      "3  tempslibre  \n",
      "4  tempslibre  \n"
     ]
    }
   ],
   "source": [
    "final_french_dataset = df_tl_fr # For now, we only have this one as the others are in english of too small and mixed with english\n",
    "final_english_dataset = pd.concat([df_tl_en, df_hn_en, df_mh_en, df_hg_eng, df_kaggle])\n",
    "\n",
    "print(f\"Final english dataset lenght : {len(final_english_dataset)}\")\n",
    "print(f\"Final french dataset lenght : {len(final_french_dataset)}\")\n",
    "\n",
    "print(final_english_dataset.head())\n",
    "print(final_french_dataset.head())\n",
    "\n",
    "final_english_dataset.to_csv('database/final_data/final_english_dataset.csv', index=False)\n",
    "final_french_dataset.to_csv('database/final_data/final_french_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may not be a lot of data, but we will work with it for now. Some websites that I tried to scrape were not easy to work with and will need to be reviewed later to add more data to the project.\n",
    "\n",
    "However, to further enhance the project, it would be beneficial to collect more data from multiple sources in both French and English.\n",
    "\n",
    "By doing so, we can improve the diversity and quality of the haikus, leading to better training for our models and generating more accurate results.\n",
    "\n",
    "Additionally, this will give me a chance to get even better at web scraping and learn more about this field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating hashes for our haikus \n",
    "\n",
    "Creating hashes for our Haikus allows us to efficiently identify and remove duplicate entries. \n",
    "\n",
    "By generating a unique hash for each Haiku based on its content, we can easily compare and filter out duplicates, ensuring that our dataset is clean and contains only unique Haikus. \n",
    "\n",
    "This will allow us to check our dataset and ensure a better training of the models latter on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English dataset lenght before duplicates dropping : 156806\n",
      "French dataset lenght before duplicates dropping : 9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(149193, 8364)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "english_haikus = pd.read_csv('database/final_data/final_english_dataset.csv')\n",
    "french_haikus = pd.read_csv('database/final_data/final_french_dataset.csv')\n",
    "\n",
    "print(f\"English dataset lenght before duplicates dropping : {len(english_haikus)}\")\n",
    "print(f\"French dataset lenght before duplicates dropping : {len(french_haikus)}\")\n",
    "\n",
    "# Process English Haikus\n",
    "# TODO : check the hashes generation to avoid punctuation and spaces in the hash\n",
    "english_haikus['hash'] = (english_haikus['line_1'] + english_haikus['line_2'] + english_haikus['line_3']).str.replace(r'[^A-Za-z]', '').str.upper()\n",
    "english_haikus = english_haikus.drop_duplicates(subset=['hash'])\n",
    "english_haikus = english_haikus.drop(columns=['hash'])\n",
    "\n",
    "# Process French Haikus\n",
    "french_haikus['hash'] = (french_haikus['line_1'] + french_haikus['line_2'] + french_haikus['line_3']).str.replace(r'[^A-Za-z]', '').str.upper()\n",
    "french_haikus = french_haikus.drop_duplicates(subset=['hash'])\n",
    "french_haikus = french_haikus.drop(columns=['hash'])\n",
    "\n",
    "# Display the processed DataFrames\n",
    "len(english_haikus), len(french_haikus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets verifications\n",
    "\n",
    "Here, we are detecting and handling problematic lines to ensure the integrity of our Haiku datasets. \n",
    "\n",
    "By identifying lines that are not strings or contain NaN values, we can drop them from our data and by doing so, prevent them from affecting our treatment and training. \n",
    "\n",
    "Dropping rows with NaN values and detecting problematic lines helps maintain a clean dataset, which is crucial for the next steps of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Function to detect problematic lines\n",
    "def detect_problematic_lines(df):\n",
    "    problematic_lines = []\n",
    "    for i in range(1, 4):\n",
    "        for index, value in df[f'line_{i}'].items():\n",
    "            if not isinstance(value, str) or pd.isna(value):\n",
    "                print(f\"Line {i} of haiku {index} is not a string or is NaN\")\n",
    "                print(value)\n",
    "                problematic_lines.append((index, f'line_{i}', value))\n",
    "    return problematic_lines\n",
    "\n",
    "# Drop rows with NaN values in 'line_1', 'line_2', or 'line_3'\n",
    "english_haikus = english_haikus.dropna(subset=['line_1', 'line_2', 'line_3'])\n",
    "french_haikus = french_haikus.dropna(subset=['line_1', 'line_2', 'line_3'])\n",
    "\n",
    "# Detect problematic lines\n",
    "english_problematic_lines = detect_problematic_lines(english_haikus)\n",
    "french_problematic_lines = detect_problematic_lines(french_haikus)\n",
    "\n",
    "# Display the problematic lines\n",
    "print(english_problematic_lines)\n",
    "print(french_problematic_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sylabus counting\n",
    "\n",
    "Counting syllables in Haikus is essential to ensure they adhere to the traditional 5-7-5 syllable structure and to test some new things with our models later on by tweaking those values. \n",
    "\n",
    "Even if here, they do not all have this specific structure, it will help the model to understand the format of the data that it is training on and that it will have to generate after.\n",
    "\n",
    "This step is quite important for the treatment of our data and to make it understandable for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             line_1                    line_2             line_3      source  \\\n",
      "0     zen garden --  stirring a passing cloud          in my tea  tempslibre   \n",
      "1  mosquee blackout               I come home  with new slippers  tempslibre   \n",
      "2     fishing boats                 colors of        the rainbow  tempslibre   \n",
      "3   ash wednesday--       trying to remember            my dream  tempslibre   \n",
      "4      snowy morn--       pouring another cup    of black coffee  tempslibre   \n",
      "\n",
      "   line1_syllables  line2_syllables  line3_syllables  \n",
      "0                3                6                3  \n",
      "1                4                5                4  \n",
      "2                3                3                3  \n",
      "3                4                5                2  \n",
      "4                3                6                4  \n",
      "                       line_1                  line_2                 line_3  \\\n",
      "0     Sur une colonne en bois  le vendeur des ballons    hisse ses souffles    \n",
      "1  Nuit froide marchant seule  d'une maison une odeur  de beignets au sucre    \n",
      "2              brume matinale   dans la tasse de café    la buée de l’arome    \n",
      "3            averse au jardin    elle a fait naufrage   la tarte aux pommes    \n",
      "4                  sécheresse      dans l’eau vaseuse         un ibis blanc    \n",
      "\n",
      "       source  line1_syllables  line2_syllables  line3_syllables  \n",
      "0  tempslibre                8                6                5  \n",
      "1  tempslibre                7                8                6  \n",
      "2  tempslibre                6                6                7  \n",
      "3  tempslibre                6                7                6  \n",
      "4  tempslibre                3                5                4  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import syllables\n",
    "\n",
    "# Function to count syllables in each line and sum them\n",
    "def count_and_sum_syllables(df):\n",
    "    df['line1_syllables'] = df['line_1'].apply(syllables.estimate)\n",
    "    df['line2_syllables'] = df['line_2'].apply(syllables.estimate)\n",
    "    df['line3_syllables'] = df['line_3'].apply(syllables.estimate)\n",
    "    return df\n",
    "\n",
    "# Drop rows with NaN values in 'line_1', 'line_2', or 'line_3'\n",
    "english_haikus = english_haikus.dropna(subset=['line_1', 'line_2', 'line_3'])\n",
    "french_haikus = french_haikus.dropna(subset=['line_1', 'line_2', 'line_3'])\n",
    "\n",
    "# Count and sum syllables\n",
    "english_haikus = count_and_sum_syllables(english_haikus)\n",
    "french_haikus = count_and_sum_syllables(french_haikus)\n",
    "\n",
    "# Display the processed DataFrames\n",
    "print(english_haikus.head())\n",
    "print(french_haikus.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a dataset\n",
    "def final_process_haikus(df):\n",
    "    # Compute the mean of syllables\n",
    "    mean_syllables = np.mean(df[['line1_syllables', 'line2_syllables', 'line3_syllables']], axis=1)\n",
    "\n",
    "    # Define the acceptable range of syllables\n",
    "    lower_bound = 3\n",
    "    upper_bound = 9\n",
    "\n",
    "    # Filter out haikus with syllables outside the acceptable range\n",
    "    filtered_haikus = df[(mean_syllables >= lower_bound) & (mean_syllables <= upper_bound)]\n",
    "\n",
    "    # Print the new length of the dataset\n",
    "    print(f\"New length of dataset: {len(filtered_haikus)}\")\n",
    "\n",
    "    # Check for NaN values\n",
    "    nan_rows = filtered_haikus[filtered_haikus.isna().any(axis=1)]\n",
    "    print(f\"Number of rows with NaN values: {len(nan_rows)}\")\n",
    "\n",
    "    return filtered_haikus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New length of dataset: 140148\n",
      "Number of rows with NaN values: 0\n",
      "New length of dataset: 8300\n",
      "Number of rows with NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "# Process both datasets\n",
    "filtered_english_haikus = final_process_haikus(english_haikus)\n",
    "filtered_french_haikus = final_process_haikus(french_haikus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_english_haikus.to_csv('database/final_data/final_english_dataset.csv', index=False)\n",
    "filtered_french_haikus.to_csv('database/final_data/final_french_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haikus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
